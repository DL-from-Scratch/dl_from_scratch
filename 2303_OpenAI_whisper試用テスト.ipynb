{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPTが生成したサンプルコードを実際に試す →失敗"
      ],
      "metadata": {
        "id": "3tupjpcwgbFI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blcmWvo3Xxic",
        "outputId": "0cac8ce6-7f4d-4ab4-9017-93dc6da4fa6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from whisper) (1.15.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41134 sha256=7996660022e7543385437e1b028e194044071291f78f5810133b5b8a3b25194f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/01/8c/1b449563518aa0f8813d044f7a910884e3b8313711becb66d6\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n"
          ]
        }
      ],
      "source": [
        "!pip install whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 確認用\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gqxSDCDaQwh",
        "outputId": "180dc969-5108-48a1-9799-4896f4cdb026"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  test-data1.m4a  test-data1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "transcript = whisper.transcribe(audio_file, model='large', lang='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "hyS9y-X3aWvS",
        "outputId": "036a6066-519d-48a7-cb36-5159a61d69fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4dbebbc1a288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Whisperを使用して音声ファイルを文字起こしする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'whisper' has no attribute 'transcribe'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "transcript = whisper.recognize_google(audio_file, model='large', lang='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "6-lzQ_aAaXv3",
        "outputId": "d10d4c28-2308-47dc-99bf-856f1dff7566"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a01f8cc51d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Whisperを使用して音声ファイルを文字起こしする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'whisper' has no attribute 'recognize_google'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "transcript = whisper.recognize(audio_file, model='google', lang='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "n6wPkH9Qh3MT",
        "outputId": "d3f473c1-428c-4242-db44-587fe297b92d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7d26efe93976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Whisperを使用して音声ファイルを文字起こしする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'whisper' has no attribute 'recognize'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "transcript = whisper.transcribe(audio_file, model='google', lang='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "6hRKW9T3h3FB",
        "outputId": "705efa74-3da5-4c0f-916b-8d2d338d2f05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-595605daea8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Whisperを使用して音声ファイルを文字起こしする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'whisper' has no attribute 'transcribe'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPTが追加で回答したSpeechRecognitionの利用へ変更 →成功\n",
        "ChatGPTが方針転換して追加で回答したSpeechRecognitionの利用に従ってみる。"
      ],
      "metadata": {
        "id": "DTRLoh0bjUuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcUQAOjTeJCE",
        "outputId": "1aca2540-bfff-469e-f7e1-37d54bcd469d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# 音声認識器を初期化する\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# 音声ファイルからオーディオを読み込む\n",
        "with sr.AudioFile(audio_file) as source:\n",
        "    audio = r.record(source)  # 全部読み取る\n",
        "\n",
        "# 音声を文字列に変換する\n",
        "text = r.recognize_google(audio, language='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qax8v8--fsNO",
        "outputId": "5086a4a9-03db-4445-d8f2-d2bc486bb003"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript: これは蒸しパン ライバルのテストです 昨日 豊富なもの の欠点 複数の欠点もある ovi はちゃんと GPT が時によってはもっともらしく見えると謝っている 解答作成することを認めているチャット GPT の報酬も電波人間による短所 中心としているため 最適化 再設定 パフォーマンスに影響を及ぼしてしまうグッド ハートの法則 それに加えチャット GPT は 2011年以降に発生したということについては 知識が蓄えられて終わらせする の著名人については 知識が全くないこともある\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "エラーなく実行可能。結果は: 誤りが多い印象。\n",
        "\n",
        "Transcript: これは蒸しパン ライバルのテストです 昨日 豊富なもの 複数の欠点もある ovi はちゃんと GPT が時によってはもっともらしく見えると謝っている 解答作成することを認めているチャット GPT の報酬も電波人間による短所 中心としているため 最適化 再設定 パフォーマンスに影響を及ぼしてしまうグッド ハートの法則 それに加えチャット GPT は 2011年以降に発生したということについては 知識が蓄えられて終わらせする の著名人については 知識が全くないこともある"
      ],
      "metadata": {
        "id": "N5YrTmphxGIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# 音声認識器を初期化する\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# 音声ファイルからオーディオを読み込む\n",
        "with sr.AudioFile(audio_file) as source:\n",
        "    audio = r.record(source)  # 全部読み取る\n",
        "\n",
        "# 音声を文字列に変換する\n",
        "text = r.recognize_bing(audio, language='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "-y7CfjB6gIkH",
        "outputId": "846ce0e7-69fa-4058-d4e4-388751d64776"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0897b5c90e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 音声を文字列に変換する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_bing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: recognize_bing() missing 1 required positional argument: 'key'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPTの回答に従い、recognize_bingを試すと、API keyが必要となる模様。"
      ],
      "metadata": {
        "id": "D_ATEh52xhq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# 音声認識器を初期化する\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# 音声ファイルからオーディオを読み込む\n",
        "with sr.AudioFile(audio_file) as source:\n",
        "    audio = r.record(source)  # 全部読み取る\n",
        "\n",
        "# 音声を文字列に変換する\n",
        "text = r.recognize_sphinx(audio, language='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "qJllW1yfgIbG",
        "outputId": "336903da-b15a-4900-9b8c-532d5aaa182d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mrecognize_sphinx\u001b[0;34m(self, audio_data, language, keyword_entries, grammar, show_all)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mpocketsphinx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpocketsphinx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJsgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFsgModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pocketsphinx'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRequestError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6ca9f9671bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 音声を文字列に変換する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_sphinx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mrecognize_sphinx\u001b[0;34m(self, audio_data, language, keyword_entries, grammar, show_all)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"missing PocketSphinx module: ensure that PocketSphinx is set up correctly.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad PocketSphinx installation; try reinstalling PocketSphinx version 0.0.9 or better.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRequestError\u001b[0m: missing PocketSphinx module: ensure that PocketSphinx is set up correctly."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPTの回答に従い、recognize_sphinxを試すと、追加のモジュールが必要となる模様。"
      ],
      "metadata": {
        "id": "TQoyTQnQxwy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 通常通り手動でWeb検索を用いて調べて試す →成功\n",
        "\n",
        "https://happy-shibusawake.com/openai_whisper/696/\n",
        "\n",
        "> Whisperと関連ライブラリのインストール\n",
        "Whisperと関連ライブラリをpipコマンドでインストールします。足りないライブラリとWhisperをインストールしてくれます。\n",
        "pip install git+https://github.com/openai/whisper.git \n",
        "Installing collected packages: more-itertools, ffmpeg-python, whisper\n",
        "Successfully installed ffmpeg-python-0.2.0 more-itertools-8.14.0 whisper-1.0\n",
        "これでインストール完了です。\n",
        "\n",
        "https://www.kkaneko.jp/ai/win/whisper.html\n",
        "\n",
        "> ダウンロードとインストール\n",
        "python -m pip install -U git+https://github.com/openai/whisper.git\n",
        "関連ファイルをダウンロード\n",
        "cd %HOMEPATH%\n",
        "rmdir /s /q whisper\n",
        "git clone --recursive https://github.com/openai/whisper.git\n",
        "\n",
        "https://qiita.com/miyanaga/items/d785f8c613da9daf1d76\n",
        "\n",
        "> Whisperで文字起こし\n",
        "このようなPythonスクリプトで文字起こししました。こんな短いプログラムでできるなんてすごい！\n",
        "import whisper\n",
        "model = whisper.load_model(\"large\")\n",
        "result = model.transcribe(\"./1st.mov\", verbose=True, language='ja')\n",
        "text = result['text']\n",
        "print(text)"
      ],
      "metadata": {
        "id": "StDEQYXJ5bZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "VHPCL04T-UHX",
        "outputId": "51c58c0d-ffe9-4021-b9a5-526418d7072c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ne4dafhh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ne4dafhh\n",
            "  Resolved https://github.com/openai/whisper.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.2.0)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.10.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Collecting lit\n",
            "  Downloading lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (63.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796926 sha256=41c5cdc72edb540a10272a03e838fe6e914b4c0c9d02d4894dc1cca091348af5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9bsv5zvb/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=90003 sha256=0538e883a4dc0fb2e8268687e1a7b8b5dd0c3e804f20fb661f9e1325ffb4c380\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/68/18/2ad49b416abb9139c8217c349fd9df0674da8f0d1952db2ea5\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, triton, tiktoken, openai-whisper\n",
            "Successfully installed lit-15.0.7 openai-whisper-20230314 tiktoken-0.3.1 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "whisper"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large\")\n",
        "result = model.transcribe(\"test-data1.wav\", verbose=True, language='ja')\n",
        "text = result['text']\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "airOMx965ZeN",
        "outputId": "f7bfde29-818a-4e6d-e9c0-7ac05004db03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:29<00:00, 104MiB/s]\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:08.040] これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点\n",
            "[00:08.040 --> 00:12.960] もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている\n",
            "[00:12.960 --> 00:17.400] 回答を作成することを認めている ChatGPTの方針モデルは人間による\n",
            "[00:17.400 --> 00:22.600] 監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまう\n",
            "[00:22.600 --> 00:27.200] グッドハートの法則 それに加え ChatGPTは2011年以降に発生した\n",
            "[00:27.200 --> 00:31.320] 出来事については知識が蓄えられて 終わらず 一部の著名人については\n",
            "[00:31.320 --> 00:32.880] 知識が全くないこともある\n",
            "これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている回答を作成することを認めている ChatGPTの方針モデルは人間による監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまうグッドハートの法則 それに加え ChatGPTは2011年以降に発生した出来事については知識が蓄えられて 終わらず 一部の著名人については知識が全くないこともある\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "エラーなく実行可能。結果は: かなり良好。\n",
        "\n",
        "これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている回答を作成することを認めている ChatGPTの方針モデルは人間による監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまうグッドハートの法則 それに加え ChatGPTは2011年以降に発生した出来事については知識が蓄えられて 終わらず 一部の著名人については知識が全くないこともある"
      ],
      "metadata": {
        "id": "fi9Xv5gBAwvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# これを踏まえて再度、ChatGPTが生成したサンプルコードを修正しながら試す →成功\n",
        "\n",
        "ChatGPTの回答は、まずインストールするライブラリが間違っており、実行が出来なかった模様。→修正してインストール(上記で済み)"
      ],
      "metadata": {
        "id": "nlti4r1iBfG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "transcript = whisper.transcribe(audio_file, model='large', lang='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "S4cLF6l8ByhV",
        "outputId": "75c65495-e275-4e29-ee85-e21a40b17f63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4dbebbc1a288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Whisperを使用して音声ファイルを文字起こしする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: transcribe() got multiple values for argument 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPTの回答は、whisper.transcribeは、引数にmodel='large'を取らない模様。→修正"
      ],
      "metadata": {
        "id": "dr3KsbuxCqIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "model = whisper.load_model(\"large\")\n",
        "transcript = model.transcribe(audio_file, lang='ja-JP')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "MXfkQvV9CrL3",
        "outputId": "d3730b3a-2377-42fa-ee7c-d09c32fea70b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-53ff1f365839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Whisperを使用して音声ファイルを文字起こしする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja-JP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 認識されたテキストを表示する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'lang'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPTの回答は、whisper.transcribeは、引数にlang='ja-JP'を取らない模様。→修正"
      ],
      "metadata": {
        "id": "QG5DXM0bJV3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# 音声ファイルを読み込む\n",
        "audio_file = 'test-data1.wav'\n",
        "\n",
        "# Whisperを使用して音声ファイルを文字起こしする\n",
        "model = whisper.load_model(\"large\")\n",
        "transcript = model.transcribe(audio_file, language='ja')\n",
        "\n",
        "# 認識されたテキストを表示する\n",
        "print('Transcript: {}'.format(transcript))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK-o3NQmJVNl",
        "outputId": "340c82af-e568-4cd8-f183-b64fb20b406f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript: {'text': 'これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている回答を作成することを認めている ChatGPTの方針モデルは人間による監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまうグッドハートの法則 それに加え ChatGPTは2011年以降に発生した出来事については知識が蓄えられて 終わらず 一部の著名人については知識が全くないこともある', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 8.040000000000001, 'text': 'これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点', 'tokens': [50364, 25212, 2471, 271, 610, 12806, 2972, 22985, 40498, 4767, 220, 17543, 8225, 3065, 19517, 232, 47564, 3203, 44726, 2972, 220, 164, 97, 229, 33188, 2972, 5988, 254, 12579, 50766], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 1, 'seek': 0, 'start': 8.040000000000001, 'end': 12.96, 'text': 'もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている', 'tokens': [50766, 4801, 24719, 7238, 48698, 3065, 41683, 38, 47, 51, 5142, 6611, 4108, 5591, 6102, 20785, 8661, 4801, 5154, 26568, 10470, 44547, 5142, 3549, 97, 6102, 22979, 51012], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 2, 'seek': 0, 'start': 12.96, 'end': 17.400000000000002, 'text': '回答を作成することを認めている ChatGPTの方針モデルは人間による', 'tokens': [51012, 8350, 28223, 5998, 11914, 11336, 22570, 13235, 5998, 22041, 38975, 22979, 27503, 38, 47, 51, 2972, 9249, 5873, 251, 29183, 31327, 9405, 3065, 4035, 11016, 4108, 5591, 4895, 51234], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 3, 'seek': 0, 'start': 17.400000000000002, 'end': 22.6, 'text': '監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまう', 'tokens': [51234, 5419, 96, 27333, 5998, 5975, 7945, 3193, 8822, 22979, 49983, 220, 8661, 41377, 220, 23756, 6722, 4132, 2659, 44601, 2996, 23268, 17320, 824, 102, 3384, 13258, 4824, 9550, 4108, 16820, 13665, 123, 5998, 25703, 487, 120, 8822, 45349, 2646, 51494], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 4, 'seek': 0, 'start': 22.6, 'end': 27.2, 'text': 'グッドハートの法則 それに加え ChatGPTは2011年以降に発生した', 'tokens': [51494, 23839, 8276, 11195, 15927, 38551, 2972, 11148, 46225, 47765, 4108, 9990, 6474, 27503, 38, 47, 51, 3065, 2009, 5348, 5157, 3588, 47421, 4108, 44756, 8244, 8533, 51724], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 5, 'seek': 2720, 'start': 27.2, 'end': 31.32, 'text': '出来事については知識が蓄えられて 終わらず 一部の著名人については', 'tokens': [50364, 44561, 6973, 4108, 9335, 18549, 3065, 6498, 43143, 5142, 39198, 226, 6474, 5154, 26638, 220, 29371, 9206, 5154, 18216, 26923, 13470, 2972, 19382, 15940, 4035, 4108, 9335, 18549, 3065, 50570], 'temperature': 0.0, 'avg_logprob': -0.2219417039738145, 'compression_ratio': 1.190909090909091, 'no_speech_prob': 0.914054811000824}, {'id': 6, 'seek': 2720, 'start': 31.32, 'end': 32.879999999999995, 'text': '知識が全くないこともある', 'tokens': [50570, 6498, 43143, 5142, 11319, 6134, 9311, 13235, 4801, 24719, 50648], 'temperature': 0.0, 'avg_logprob': -0.2219417039738145, 'compression_ratio': 1.190909090909091, 'no_speech_prob': 0.914054811000824}], 'language': 'ja'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "エラーなく実行可能となる。結果は: 前回と同様。かなり良好。\n",
        "\n",
        "Transcript: {'text': 'これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている回答を作成することを認めている ChatGPTの方針モデルは人間による監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまうグッドハートの法則 それに加え ChatGPTは2011年以降に発生した出来事については知識が蓄えられて 終わらず 一部の著名人については知識が全くないこともある', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 8.040000000000001, 'text': 'これはWhisper Libraryのテストです 機能は豊富なものの 複数の欠点', 'tokens': [50364, 25212, 2471, 271, 610, 12806, 2972, 22985, 40498, 4767, 220, 17543, 8225, 3065, 19517, 232, 47564, 3203, 44726, 2972, 220, 164, 97, 229, 33188, 2972, 5988, 254, 12579, 50766], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 1, 'seek': 0, 'start': 8.040000000000001, 'end': 12.96, 'text': 'もある OpenAIはChatGPTが時によって は最もらしく見えるが誤っている', 'tokens': [50766, 4801, 24719, 7238, 48698, 3065, 41683, 38, 47, 51, 5142, 6611, 4108, 5591, 6102, 20785, 8661, 4801, 5154, 26568, 10470, 44547, 5142, 3549, 97, 6102, 22979, 51012], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 2, 'seek': 0, 'start': 12.96, 'end': 17.400000000000002, 'text': '回答を作成することを認めている ChatGPTの方針モデルは人間による', 'tokens': [51012, 8350, 28223, 5998, 11914, 11336, 22570, 13235, 5998, 22041, 38975, 22979, 27503, 38, 47, 51, 2972, 9249, 5873, 251, 29183, 31327, 9405, 3065, 4035, 11016, 4108, 5591, 4895, 51234], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 3, 'seek': 0, 'start': 17.400000000000002, 'end': 22.6, 'text': '監視を中心としているため 最低 化されすぎてパフォーマンスに影響を及ぼしてしまう', 'tokens': [51234, 5419, 96, 27333, 5998, 5975, 7945, 3193, 8822, 22979, 49983, 220, 8661, 41377, 220, 23756, 6722, 4132, 2659, 44601, 2996, 23268, 17320, 824, 102, 3384, 13258, 4824, 9550, 4108, 16820, 13665, 123, 5998, 25703, 487, 120, 8822, 45349, 2646, 51494], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 4, 'seek': 0, 'start': 22.6, 'end': 27.2, 'text': 'グッドハートの法則 それに加え ChatGPTは2011年以降に発生した', 'tokens': [51494, 23839, 8276, 11195, 15927, 38551, 2972, 11148, 46225, 47765, 4108, 9990, 6474, 27503, 38, 47, 51, 3065, 2009, 5348, 5157, 3588, 47421, 4108, 44756, 8244, 8533, 51724], 'temperature': 0.0, 'avg_logprob': -0.17137325934644015, 'compression_ratio': 1.3304597701149425, 'no_speech_prob': 0.03912182152271271}, {'id': 5, 'seek': 2720, 'start': 27.2, 'end': 31.32, 'text': '出来事については知識が蓄えられて 終わらず 一部の著名人については', 'tokens': [50364, 44561, 6973, 4108, 9335, 18549, 3065, 6498, 43143, 5142, 39198, 226, 6474, 5154, 26638, 220, 29371, 9206, 5154, 18216, 26923, 13470, 2972, 19382, 15940, 4035, 4108, 9335, 18549, 3065, 50570], 'temperature': 0.0, 'avg_logprob': -0.2219417039738145, 'compression_ratio': 1.190909090909091, 'no_speech_prob': 0.914054811000824}, {'id': 6, 'seek': 2720, 'start': 31.32, 'end': 32.879999999999995, 'text': '知識が全くないこともある', 'tokens': [50570, 6498, 43143, 5142, 11319, 6134, 9311, 13235, 4801, 24719, 50648], 'temperature': 0.0, 'avg_logprob': -0.2219417039738145, 'compression_ratio': 1.190909090909091, 'no_speech_prob': 0.914054811000824}], 'language': 'ja'}"
      ],
      "metadata": {
        "id": "Mzy4JvsdK3aT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 前処理: .wavファイルへ変換"
      ],
      "metadata": {
        "id": "Iueq1SdMftHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzC6YaNRfq6N",
        "outputId": "6acc7ea1-e5f2-481e-ea63-54c93c1fe131"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "stream = ffmpeg.input(\"test-data1.m4a\")\n",
        "stream = ffmpeg.output(stream, \"test-data1.wav\")\n",
        "ffmpeg.run(stream)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQL4RUArfyta",
        "outputId": "f40e1e76-e460-4eb6-b959-8302f9beacf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mURtAAHif9VM",
        "outputId": "dda2624c-6b31-44fa-f7e0-e1f11b5f543e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  test-data1.m4a  test-data1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".wavへ変換成功"
      ],
      "metadata": {
        "id": "BdFhKmOdyFqk"
      }
    }
  ]
}